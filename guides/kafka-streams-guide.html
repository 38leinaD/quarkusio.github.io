<!DOCTYPE html>
<html>

<head>
  <title>Quarkus - Using Apache Kafka Streams</title>
  <script id="adobe_dtm" src="//www.redhat.com/dtm.js" type="text/javascript"></script>
  <script src="/assets/javascript/highlightjs-pack.js" type="text/javascript"></script>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Quarkus: Supersonic Subatomic Java">
  <link rel="shortcut icon" type="image/png" href="/favicon.ico" >
  <link rel="stylesheet" href="/assets/css/main.css" />
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.1.0/css/all.css" integrity="sha384-lKuwvrZot6UHsBSfcMvOkWwlCMgc0TaWr+30HWe3a4ltaBwTZhyTEggF5tJv8tbt" crossorigin="anonymous">
  <link rel="alternate" type="application/rss+xml"  href="https://quarkus.io//feed.xml" title="Quarkus">
  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-NJWS5L');</script>
  <!-- End Google Tag Manager -->
  <!-- Syntax highlighting -->
  <script>hljs.initHighlightingOnLoad();</script>
</head>

<body class="guides">
  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NJWS5L"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

  <div class="content">
    <div class="navigation-wrapper">
  <div class="width-12-12">
    <div class="header navigation">
      <div class="logo-wrapper">
        <a href="/"><img src="/assets/images/quarkus_logo_horizontal_rgb_reverse.svg" class="project-logo" title="Quarkus"></a>
      </div>
      <div class="nav-container">
        <nav>
          <div class="nav-mobile"><a id="nav-toggle" href="#!"><span></span></a></div>
          <ul class="nav-list">
            <li>
              <a href="/get-started/" class="">Get Started</a>
            </li>
            <li>
              <a href="/guides/" class="active">Guides</a>
            </li>
            <li>
              <a href="/extensions/" class="">Extensions</a>
            </li>
            <li>
              <a href="/community/" class="">Community</a>
            </li>
            <li>
              <a href="/blog/" class="">Blog</a>
            </li>
          </ul>
        </nav>
      </div>
    </div>
  </div>
</div>

    <div class="guides">
  <div class="width-12-12">
    <h1 class="text-caps">Quarkus - Using Apache Kafka Streams</h1>
    <div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>This guide demonstrates how your Quarkus application can utilize the Apache Kafka Streams API to implement stream processing applications based on Apache Kafka.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="prerequisites">Prerequisites</h2>
<div class="sectionbody">
<div class="paragraph">
<p>To complete this guide, you need:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>less than 30 minutes</p>
</li>
<li>
<p>an IDE</p>
</li>
<li>
<p>JDK 1.8+ installed with <code>JAVA_HOME</code> configured appropriately</p>
</li>
<li>
<p>Apache Maven 3.5.3+</p>
</li>
<li>
<p>Docker Compose to start an Apache Kafka development cluster</p>
</li>
<li>
<p>GraalVM installed if you want to run in native mode.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>It is recommended, that you have read the <a href="https://github.com/quarkusio/quarkus-quickstarts/tree/master/kafka-quickstart">Kafka quickstart</a> before.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="architecture">Architecture</h2>
<div class="sectionbody">
<div class="paragraph">
<p>In this guide, we are going to generate (random) temperature values in one component (named <code>generator</code>).
These values are associated to given weather stations and are written in a Kafka topic (<code>temperature-values</code>).
Another topic (<code>weather-stations</code>) contains just the master data about the weather stations themselves (id and name).</p>
</div>
<div class="paragraph">
<p>A second component (<code>aggregator</code>) reads from the two Kafka topics and processes them in a streaming pipeline:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>the two topics are joined on weather station id</p>
</li>
<li>
<p>per weather station the min, max and average temperature is determined</p>
</li>
<li>
<p>this aggregated data is written out to a third topic (<code>temperatures-aggregated</code>)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The data can be examined by inspecting the output topic.
By exposing a Kafka Streams <a href="https://kafka.apache.org/22/documentation/streams/developer-guide/interactive-queries.html">interactive query</a>,
the latest result for each weather station can alternatively be obtained via a simple REST query.</p>
</div>
<div class="paragraph">
<p>The overall architecture looks like so:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/guides/images/kafka-streams-guide-architecture.png" alt="Architecture">
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="solution">Solution</h2>
<div class="sectionbody">
<div class="paragraph">
<p>We recommend that you follow the instructions in the next sections and create the application step by step.
However, you can go right to the completed example.</p>
</div>
<div class="paragraph">
<p>Clone the Git repository: <code>git clone <a href="https://github.com/quarkusio/quarkus-quickstarts.git" class="bare">https://github.com/quarkusio/quarkus-quickstarts.git</a></code>, or download an <a href="https://github.com/quarkusio/quarkus-quickstarts/archive/master.zip">archive</a>.</p>
</div>
<div class="paragraph">
<p>The solution is located in the <code>kafka-streams-quickstart</code> <a href="https://github.com/quarkusio/quarkus-quickstarts/tree/master/kafka-streams-quickstart">directory</a>.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="creating-the-producer-maven-project">Creating the Producer Maven Project</h2>
<div class="sectionbody">
<div class="paragraph">
<p>First, we need a new project with the temperature value producer.
Create a new project with the following command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">mkdir producer &amp;&amp; cd producer &amp;&amp; \
mvn io.quarkus:quarkus-maven-plugin:0.17.0:create \
    -DprojectGroupId=org.acme \
    -DprojectArtifactId=kafka-streams-quickstart-producer \
    -Dextensions="kafka" \
    &amp;&amp; cd ..</code></pre>
</div>
</div>
<div class="paragraph">
<p>This command generates a Maven project, importing the Reactive Messaging and Kafka connector extensions.</p>
</div>
<div class="sect2">
<h3 id="the-temperature-value-producer">The Temperature Value Producer</h3>
<div class="paragraph">
<p>Create the <code>producer/src/main/java/org/acme/quarkus/sample/generator/ValuesGenerator.java</code> file,
with the following content:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code data-lang="java" class="language-java hljs">package org.acme.quarkus.sample.generator;

import java.math.BigDecimal;
import java.math.RoundingMode;
import java.time.Instant;
import java.util.Arrays;
import java.util.Collections;
import java.util.List;
import java.util.Random;
import java.util.concurrent.TimeUnit;
import java.util.stream.Collectors;

import javax.enterprise.context.ApplicationScoped;

import org.eclipse.microprofile.reactive.messaging.Outgoing;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import io.reactivex.Flowable;
import io.smallrye.reactive.messaging.kafka.KafkaMessage;

/**
 * A bean producing random temperature data every second.
 * The values are written to a Kafka topic (temperature-values).
 * Another topic contains the name of weather stations (weather-stations).
 * The Kafka configuration is specified in the application configuration.
 */
@ApplicationScoped
public class ValuesGenerator {

    private static final Logger LOG = LoggerFactory.getLogger(ValuesGenerator.class);

    private Random random = new Random();

    private List&lt;WeatherStation&gt; stations = Collections.unmodifiableList(
            Arrays.asList(
                    new WeatherStation(1, "Hamburg", 13),
                    new WeatherStation(2, "Snowdonia", 5),
                    new WeatherStation(3, "Boston", 11),
                    new WeatherStation(4, "Tokio", 16),
                    new WeatherStation(5, "Cusco", 12),
                    new WeatherStation(6, "Svalbard", -7),
                    new WeatherStation(7, "Porthsmouth", 11),
                    new WeatherStation(8, "Oslo", 7),
                    new WeatherStation(9, "Marrakesh", 20)
            ));


    @Outgoing("temperature-values")                             // <b class="conum">(1)</b>
    public Flowable&lt;KafkaMessage&lt;Integer, String&gt;&gt; generate() {

        return Flowable.interval(500, TimeUnit.MILLISECONDS)    // <b class="conum">(2)</b>
                .onBackpressureDrop()
                .map(tick -&gt; {
                    WeatherStation station = stations.get(random.nextInt(stations.size()));
                    double temperature = new BigDecimal(
                                random.nextGaussian() * 15 + station.averageTemperature
                            )
                            .setScale(1, RoundingMode.HALF_UP)
                            .doubleValue();

                    LOG.info("station: {}, temperature: {}", station.name, temperature);
                    return KafkaMessage.of(station.id, Instant.now() + ";" + temperature);
                });
    }

    @Outgoing("weather-stations")                               // <b class="conum">(3)</b>
    public Flowable&lt;KafkaMessage&lt;Integer, String&gt;&gt; weatherStations() {
        List&lt;KafkaMessage&lt;Integer, String&gt;&gt; stationsAsJson = stations.stream()
            .map(s -&gt; KafkaMessage.of(
                    s.id,
                    "{ \"id\" : " + s.id +
                    ", \"name\" : \"" + s.name + "\" }"))
            .collect(Collectors.toList());

        return Flowable.fromIterable(stationsAsJson);
    };

    private static class WeatherStation {

        int id;
        String name;
        int averageTemperature;

        public WeatherStation(int id, String name, int averageTemperature) {
            this.id = id;
            this.name = name;
            this.averageTemperature = averageTemperature;
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>Instruct Reactive Messaging to dispatch the items from the returned <code>Flowable</code> to <code>temperature-values</code>.</p>
</li>
<li>
<p>The method returns a RX Java 2 <em>stream</em> (<code>Flowable</code>) emitting a random temperature value every 0.5 seconds.</p>
</li>
<li>
<p>Instruct Reactive Messaging to dispatch the items from the returned <code>Flowable</code> (static list of weather stations) to <code>weather-stations</code>.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>The two methods each return a <em>reactive stream</em> whose items are sent to the streams named <code>temperature-values</code> and <code>weather-stations</code>, respectively.</p>
</div>
</div>
<div class="sect2">
<h3 id="topic-configuration">Topic Configuration</h3>
<div class="paragraph">
<p>The two channels are mapped to Kafka topics using the Quarkus configuration file <code>application.properties</code>.
For that, add the following to the file <code>producer/src/main/resources/application.properties</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs"># Configure the Kafka broker location
kafka.bootstrap.servers=localhost:9092

mp.messaging.outgoing.temperature-values.connector=smallrye-kafka
mp.messaging.outgoing.temperature-values.key.serializer=org.apache.kafka.common.serialization.IntegerSerializer
mp.messaging.outgoing.temperature-values.value.serializer=org.apache.kafka.common.serialization.StringSerializer

mp.messaging.outgoing.weather-stations.connector=smallrye-kafka
mp.messaging.outgoing.weather-stations.key.serializer=org.apache.kafka.common.serialization.IntegerSerializer
mp.messaging.outgoing.weather-stations.value.serializer=org.apache.kafka.common.serialization.StringSerializer</code></pre>
</div>
</div>
<div class="paragraph">
<p>This configures the Kafka bootstrap server, the two topics and the corresponding (de-)serializers.
More details about the different configuration options are available on the <a href="https://kafka.apache.org/documentation/#producerconfigs">Producer configuration</a> and <a href="https://kafka.apache.org/documentation/#consumerconfigs">Consumer configuration</a> section from the Kafka documentation.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="creating-the-aggregator-maven-project">Creating the Aggregator Maven Project</h2>
<div class="sectionbody">
<div class="paragraph">
<p>With the producer application in place, it&#8217;s time to implement the actual aggregator application,
which will run the Kafka Streams pipeline.
Create another project like so:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">mkdir aggregator &amp;&amp; cd aggregator &amp;&amp; \
mvn io.quarkus:quarkus-maven-plugin:0.17.0:create \
    -DprojectGroupId=org.acme \
    -DprojectArtifactId=kafka-streams-quickstart-aggregator \
    -Dextensions="kafka-streams,resteasy-jsonb" \
    &amp;&amp; cd ..</code></pre>
</div>
</div>
<div class="paragraph">
<p>This creates the `aggregator, project with the Quarkus extension for Kafka Streams and with RESTEasy support for JSON-B.</p>
</div>
<div class="sect2">
<h3 id="the-pipeline-implementation">The Pipeline Implementation</h3>
<div class="paragraph">
<p>Let&#8217;s begin the implementation of the stream processing application by creating
a few value objects for representing temperature measurements, weather stations and for keeping track of aggregated values.</p>
</div>
<div class="paragraph">
<p>First, create the file <code>aggregator/src/main/java/org/acme/quarkus/sample/kafkastreams/model/WeatherStation.java</code>,
representing a weather station, with the following content:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code data-lang="java" class="language-java hljs">package org.acme.quarkus.sample.kafkastreams.model;

import io.quarkus.runtime.annotations.RegisterForReflection;

@RegisterForReflection // <b class="conum">(1)</b>
public class WeatherStation {

    public int id;
    public String name;
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>By adding the <code>@RegisterForReflection</code> annotation, it is ensured that this type can be instantiated reflectively when running the application in native mode.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Then the file <code>aggregator/src/main/java/org/acme/quarkus/sample/kafkastreams/model/TemperatureMeasurement.java</code>,
representing temperature measurements for a given station:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code data-lang="java" class="language-java hljs">package org.acme.quarkus.sample.kafkastreams.model;

import java.time.Instant;

public class TemperatureMeasurement {

    public int stationId;
    public String stationName;
    public Instant timestamp;
    public double value;

    public TemperatureMeasurement(int stationId, String stationName, Instant timestamp,
            double value) {
        this.stationId = stationId;
        this.stationName = stationName;
        this.timestamp = timestamp;
        this.value = value;
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>And finally <code>aggregator/src/main/java/org/acme/quarkus/sample/kafkastreams/model/Aggregation.java</code>,
which will be used to keep track of the aggregated values while the events are processed in the streaming pipeline:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code data-lang="java" class="language-java hljs">package org.acme.quarkus.sample.kafkastreams.model;

import java.math.BigDecimal;
import java.math.RoundingMode;

import io.quarkus.runtime.annotations.RegisterForReflection;

public class Aggregation {

    public int stationId;
    public String stationName;
    public double min = Double.MAX_VALUE;
    public double max = Double.MIN_VALUE;
    public int count;
    public double sum;
    public double avg;

    public Aggregation updateFrom(TemperatureMeasurement measurement) {
        stationId = measurement.stationId;
        stationName = measurement.stationName;

        count++;
        sum += measurement.value;
        avg = BigDecimal.valueOf(sum / count)
                .setScale(1, RoundingMode.HALF_UP).doubleValue();

        min = Math.min(min, measurement.value);
        max = Math.max(max, measurement.value);

        return this;
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Next, let&#8217;s create the actual streaming query implementation itself in the <code>aggregator/src/main/java/org/acme/quarkus/sample/kafkastreams/streams/KafkaStreamsPipeline.java</code> file:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code data-lang="java" class="language-java hljs">package org.acme.quarkus.sample.kafkastreams.streams;

import java.time.Instant;
import java.util.HashMap;
import java.util.Map;
import java.util.Properties;
import java.util.Set;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;
import java.util.stream.Collectors;

import javax.enterprise.context.ApplicationScoped;
import javax.enterprise.event.Observes;

import org.acme.quarkus.sample.kafkastreams.model.Aggregation;
import org.acme.quarkus.sample.kafkastreams.model.TemperatureMeasurement;
import org.acme.quarkus.sample.kafkastreams.model.WeatherStation;
import org.apache.kafka.clients.CommonClientConfigs;
import org.apache.kafka.clients.admin.AdminClient;
import org.apache.kafka.clients.admin.ListTopicsResult;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.streams.KafkaStreams;
import org.apache.kafka.streams.StreamsBuilder;
import org.apache.kafka.streams.StreamsConfig;
import org.apache.kafka.streams.errors.InvalidStateStoreException;
import org.apache.kafka.streams.kstream.Consumed;
import org.apache.kafka.streams.kstream.GlobalKTable;
import org.apache.kafka.streams.kstream.Materialized;
import org.apache.kafka.streams.kstream.Produced;
import org.apache.kafka.streams.state.KeyValueBytesStoreSupplier;
import org.apache.kafka.streams.state.QueryableStoreTypes;
import org.apache.kafka.streams.state.ReadOnlyKeyValueStore;
import org.apache.kafka.streams.state.Stores;
import org.apache.kafka.streams.state.StreamsMetadata;
import org.eclipse.microprofile.config.inject.ConfigProperty;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import io.quarkus.runtime.ShutdownEvent;
import io.quarkus.runtime.StartupEvent;

@ApplicationScoped
public class KafkaStreamsPipeline {

    private static final String WEATHER_STATIONS_STORE = "weather-stations-store";

    private static final String WEATHER_STATIONS_TOPIC = "weather-stations";
    private static final String TEMPERATURE_VALUES_TOPIC = "temperature-values";
    private static final String TEMPERATURES_AGGREGATED_TOPIC = "temperatures-aggregated";

    private static final Logger LOG = LoggerFactory.getLogger(KafkaStreamsPipeline.class);

    @ConfigProperty(
        name="org.acme.quarkus.sample.kafkastreams.bootstrap.servers",
        defaultValue="localhost:9092"
    )
    String bootstrapServers;

    @ConfigProperty(name="HOSTNAME")                            // <b class="conum">(1)</b>
    String host;

    @ConfigProperty(name = "quarkus.http.port")                 // <b class="conum">(1)</b>
    int port;

    private KafkaStreams streams;

    private ExecutorService executor;

    void onStart(@Observes StartupEvent ev) {
        Properties props = new Properties();
        props.put(StreamsConfig.APPLICATION_ID_CONFIG, "temperature-aggregator");
        props.put(StreamsConfig.APPLICATION_SERVER_CONFIG, host + ":" + port); // <b class="conum">(1)</b>
        props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        props.put(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG, 10 * 1024);
        props.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, 1000);
        props.put(CommonClientConfigs.METADATA_MAX_AGE_CONFIG, 500);
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
        StreamsBuilder builder = new StreamsBuilder();

        JsonbSerde&lt;WeatherStation&gt; weatherStationSerde = new JsonbSerde&lt;&gt;(
                WeatherStation.class);
        JsonbSerde&lt;Aggregation&gt; aggregationSerde = new JsonbSerde&lt;&gt;(Aggregation.class);

        KeyValueBytesStoreSupplier storeSupplier = Stores.inMemoryKeyValueStore(
                WEATHER_STATIONS_STORE);

        GlobalKTable&lt;Integer, WeatherStation&gt; stations = builder.globalTable( // <b class="conum">(2)</b>
                WEATHER_STATIONS_TOPIC,
                Consumed.with(Serdes.Integer(), weatherStationSerde));

        builder.stream(                                                       // <b class="conum">(3)</b>
                        TEMPERATURE_VALUES_TOPIC,
                        Consumed.with(Serdes.Integer(), Serdes.String())
                )
                .join(                                                        // <b class="conum">(4)</b>
                        stations,
                        (stationId, timestampAndValue) -&gt; stationId,
                        (timestampAndValue, station) -&gt; {
                            String[] parts = timestampAndValue.split(";");
                            return new TemperatureMeasurement(station.id, station.name,
                                    Instant.parse(parts[0]), Double.valueOf(parts[1]));
                        }
                )
                .groupByKey()                                                 // <b class="conum">(5)</b>
                .aggregate(                                                   // <b class="conum">(6)</b>
                        Aggregation::new,
                        (stationId, value, aggregation) -&gt; aggregation.updateFrom(value),
                        Materialized.&lt;Integer, Aggregation&gt; as(storeSupplier)
                            .withKeySerde(Serdes.Integer())
                            .withValueSerde(aggregationSerde)
                )
                .toStream()
                .to(                                                          // <b class="conum">(7)</b>
                        TEMPERATURES_AGGREGATED_TOPIC,
                        Produced.with(Serdes.Integer(), aggregationSerde)
                );

        streams = new KafkaStreams(builder.build(), props);

        executor = Executors.newSingleThreadExecutor();
        executor.execute(() -&gt; {
            waitForTopicsToBeCreated(bootstrapServers);                       // <b class="conum">(8)</b>
            streams.start();
        });
    }

    void onStop(@Observes ShutdownEvent ev) {
        streams.close();
        executor.shutdown();
    }

    private void waitForTopicsToBeCreated(String bootstrapServers) {
        Map&lt;String, Object&gt; config = new HashMap&lt;&gt;();
        config.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);

        try (AdminClient adminClient = AdminClient.create(config)) {
            while (true) {
                ListTopicsResult topics = adminClient.listTopics();
                Set&lt;String&gt; topicNames = topics.names().get(60, TimeUnit.SECONDS);

                if (topicNames.contains(WEATHER_STATIONS_TOPIC) &amp;&amp;
                        topicNames.contains(TEMPERATURE_VALUES_TOPIC)) {
                    return;
                }

                LOG.info(
                    "Waiting for topics {} and {} to be created",
                    WEATHER_STATIONS_TOPIC,
                    TEMPERATURE_VALUES_TOPIC
                );
                Thread.sleep(1_000);
            }
        } catch (InterruptedException | ExecutionException | TimeoutException e) {
            throw new RuntimeException(e);
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>Host and port of the application are injected and passed to the Kafka Streams configuration as this application node&#8217;s identity; this will be used later on when running the interactive query in a distributed way</p>
</li>
<li>
<p>The <code>weather-stations</code> table is read into a <code>GlobalKTable</code>, representing the current state of each weather station</p>
</li>
<li>
<p>The <code>temperature-values</code> topic is read into a <code>KStream</code>; whenever a new message arrives to this topic, the pipeline will be processed for this measurement</p>
</li>
<li>
<p>The message from the <code>temperature-values</code> topic is joined with the corresponding weather station, using the topic&#8217;s key (weather station id); the join result contains the data from the measurement and associated weather station message</p>
</li>
<li>
<p>The values are grouped by message key (the weather station id)</p>
</li>
<li>
<p>Within each group, all the measurements of that station are aggregated, by keeping track of minimum and maxium values and calculating the average value of all measurements of that station (see the <code>Aggregation</code> type)</p>
</li>
<li>
<p>The results of the pipeline are written out to the <code>temperatures-aggregated</code> topic</p>
</li>
<li>
<p>The Quarkus <code>StartupEvent</code> and <code>ShutdownEvent</code> lifecycle events are used for starting and stopping the pipeline; as it may only be started once the topics exist, the Kafka admin client is used to check for their existence continuously, until they have been set up</p>
</li>
</ol>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="building-and-running-the-applications">Building and Running the Applications</h2>
<div class="sectionbody">
<div class="paragraph">
<p>We now can build the <code>producer</code> and <code>aggregator</code> applications:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">mvn clean package -f producer/pom.xml
mvn clean package -f aggregator/pom.xml</code></pre>
</div>
</div>
<div class="paragraph">
<p>Instead of running them directly on the host machine using the Quarkus dev mode,
we&#8217;re going to package them into container images and launch them via Docker Compose.
This is done in order to demonstrate scaling the <code>aggregator</code> aggregation to multiple nodes later on.</p>
</div>
<div class="paragraph">
<p>The <code>Dockerfile</code> created by Quarkus by default needs one adjustment for the <code>aggregator</code> application in order to run the Kafka Streams pipeline.
To do so, edit the file <code>aggregator/src/main/docker/Dockerfile.jvm</code> and replace the line <code>FROM fabric8/java-alpine-openjdk8-jre</code> with <code>FROM fabric8/java-centos-openjdk8-jdk</code>.</p>
</div>
<div class="paragraph">
<p>Next create a Docker Compose file (<code>docker-compose.yaml</code>) for spinning up the two applications as well as Apache Kafka and ZooKeeper like so:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code data-lang="yaml" class="language-yaml hljs">version: '3.5'

services:
  zookeeper:
    image: strimzi/kafka:0.11.3-kafka-2.1.0
    command: [
      "sh", "-c",
      "bin/zookeeper-server-start.sh config/zookeeper.properties"
    ]
    ports:
      - "2181:2181"
    environment:
      LOG_DIR: /tmp/logs
    networks:
      - kafkastreams-network
  kafka:
    image: strimzi/kafka:0.11.3-kafka-2.1.0
    command: [
      "sh", "-c",
      "bin/kafka-server-start.sh config/server.properties --override listeners=$${KAFKA_LISTENERS} --override advertised.listeners=$${KAFKA_ADVERTISED_LISTENERS} --override zookeeper.connect=$${KAFKA_ZOOKEEPER_CONNECT} --override num.partitions=$${KAFKA_NUM_PARTITIONS}"
    ]
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      LOG_DIR: "/tmp/logs"
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_NUM_PARTITIONS: 3
    networks:
      - kafkastreams-network

  producer:
    image: quarkus-quickstarts/kafka-streams-producer:1.0
    build:
      context: producer
      dockerfile: src/main/docker/Dockerfile.${QUARKUS_MODE:-jvm}
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
    networks:
      - kafkastreams-network

  aggregator:
    image: quarkus-quickstarts/kafka-streams-aggregator:1.0
    build:
      context: aggregator
      dockerfile: src/main/docker/Dockerfile.${QUARKUS_MODE:-jvm}
    environment:
      ORG_ACME_QUARKUS_SAMPLE_KAFKASTREAMS_BOOTSTRAP_SERVERS: kafka:9092
    networks:
      - kafkastreams-network

networks:
  kafkastreams-network:
    name: ks</code></pre>
</div>
</div>
<div class="paragraph">
<p>To launch all the containers, building the <code>producer</code> and <code>aggregator</code> container images,
run <code>docker-compose up --build</code>.</p>
</div>
<div class="paragraph">
<p>You should see log statements from the <code>producer</code> application about messages being sent to the "temperature-values" topic.
Due to an [an issue](<a href="https://github.com/smallrye/smallrye-reactive-messaging/issues/128" class="bare">https://github.com/smallrye/smallrye-reactive-messaging/issues/128</a>) in the SmallRye Reactive Messaging component it might be that the <em>producer</em> application isn&#8217;t sending events if it was started before Apache Kafka was up.
In this case, simply restart the <code>producer</code>
(run from another shell window, keeping the other services running):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">docker-compose stop producer &amp;&amp; docker-compose start producer</code></pre>
</div>
</div>
<div class="paragraph">
<p>Now run an instance of the <em>debezium/tooling</em> image, attaching to the same network all the other containers run in.
This image provides several useful tools such as <em>kafkacat</em> and <em>httpie</em>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">docker run --tty --rm -i --network ks debezium/tooling:1.0</code></pre>
</div>
</div>
<div class="paragraph">
<p>Within the tooling container, run <em>kafkacat</em> to examine the results of the streaming pipeline:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">kafkacat -b kafka:9092 -C -o beginning -q -t temperatures-aggregated

{"avg":34.7,"count":4,"max":49.4,"min":16.8,"stationId":9,"stationName":"Marrakesh","sum":138.8}
{"avg":15.7,"count":1,"max":15.7,"min":15.7,"stationId":2,"stationName":"Snowdonia","sum":15.7}
{"avg":12.8,"count":7,"max":25.5,"min":-13.8,"stationId":7,"stationName":"Porthsmouth","sum":89.7}
...</code></pre>
</div>
</div>
<div class="paragraph">
<p>You should see new values arrive as the producer continues to emit temperature measurements,
each value on the outbound topic showing the mininum, maxium and average temperature values of the represented weather station.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="interactive-queries">Interactive Queries</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Subscribing to the <code>temperatures-aggregated</code> topic is a great way to react to any new temperature values.
It&#8217;s a bit wasteful though if you&#8217;re just interested in the latest aggregated value for a given weather station.
This is where Kafka Streams interactive queries shine:
they let you directly query the underlying state store of the pipeline for the value associated to a given key.
By exposing a simple REST endpoint which queries the state store,
the latest aggregation result can be retrieved without having to subscribe to any Kafka topic.</p>
</div>
<div class="paragraph">
<p>Let&#8217;s begin by adding one more method to the <code>KafkaStreamsPipeline</code> class which obtains the current state for a given key:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code data-lang="java" class="language-java hljs">public GetWeatherStationDataResult getWeatherStationData(int id) {
    Aggregation result = getWeatherStationStore().get(id);

    if (result != null) {
        return GetWeatherStationDataResult.found(WeatherStationData.from(result)); // <b class="conum">(1)</b>
    }
    else {
        return GetWeatherStationDataResult.notFound();                             // <b class="conum">(2)</b>
    }
}

private ReadOnlyKeyValueStore&lt;Integer, Aggregation&gt; getWeatherStationStore() {
    while (true) {
        try {
            return streams.store(WEATHER_STATIONS_STORE,
                    QueryableStoreTypes.keyValueStore());
        } catch (InvalidStateStoreException e) {
            // ignore, store not ready yet
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>A value for the given station id was found, so that value will be returned</p>
</li>
<li>
<p>No value was found, either because a non-existing station was queried or no measurement exists yet for the given station</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Also create the method&#8217;s return type in the file <code>aggregator/src/main/java/org/acme/quarkus/sample/kafkastreams/streams/GetWeatherStationDataResult.java</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code data-lang="java" class="language-java hljs">package org.acme.quarkus.sample.kafkastreams.streams;

import java.util.Optional;
import java.util.OptionalInt;

import org.acme.quarkus.sample.kafkastreams.model.WeatherStationData;

public class GetWeatherStationDataResult {

    private static GetWeatherStationDataResult NOT_FOUND =
            new GetWeatherStationDataResult(null);

    private final WeatherStationData result;

    private GetWeatherStationDataResult(WeatherStationData result) {
        this.result = result;
    }

    public static GetWeatherStationDataResult found(WeatherStationData data) {
        return new GetWeatherStationDataResult(data);
    }

    public static GetWeatherStationDataResult notFound() {
        return NOT_FOUND;
    }

    public Optional&lt;WeatherStationData&gt; getResult() {
        return Optional.ofNullable(result);
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Also create <code>aggregator/src/main/java/org/acme/quarkus/sample/kafkastreams/model/WeatherStationData.java</code>,
which represents the actual aggregation result for a weather station:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code data-lang="java" class="language-java hljs">package org.acme.quarkus.sample.kafkastreams.model;

public class WeatherStationData {

    public int stationId;
    public String stationName;
    public double min = Double.MAX_VALUE;
    public double max = Double.MIN_VALUE;
    public int count;
    public double avg;

    private WeatherStationData(int stationId, String stationName, double min, double max,
            int count, double avg) {
        this.stationId = stationId;
        this.stationName = stationName;
        this.min = min;
        this.max = max;
        this.count = count;
        this.avg = avg;
    }

    public static WeatherStationData from(Aggregation aggregation) {
        return new WeatherStationData(
                aggregation.stationId,
                aggregation.stationName,
                aggregation.min,
                aggregation.max,
                aggregation.count,
                aggregation.avg);
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>We now can add a simple REST endpoint (<code>aggregator/src/main/java/org/acme/quarkus/sample/kafkastreams/rest/WeatherStationEndpoint.java</code>),
which invokes <code>getWeatherStationData()</code> and returns the data to the client:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code data-lang="java" class="language-java hljs">package org.acme.quarkus.sample.kafkastreams.rest;

import java.net.URI;
import java.net.URISyntaxException;
import java.util.List;

import javax.enterprise.context.ApplicationScoped;
import javax.inject.Inject;
import javax.ws.rs.Consumes;
import javax.ws.rs.GET;
import javax.ws.rs.Path;
import javax.ws.rs.PathParam;
import javax.ws.rs.Produces;
import javax.ws.rs.core.MediaType;
import javax.ws.rs.core.Response;
import javax.ws.rs.core.Response.Status;

import org.acme.quarkus.sample.kafkastreams.streams.GetWeatherStationDataResult;
import org.acme.quarkus.sample.kafkastreams.streams.KafkaStreamsPipeline;

@ApplicationScoped
@Path("/weather-stations")
public class WeatherStationEndpoint {

    @Inject
    KafkaStreamsPipeline pipeline;

    @GET
    @Path("/data/{id}")
    @Consumes(MediaType.APPLICATION_JSON)
    @Produces(MediaType.APPLICATION_JSON)
    public Response getWeatherStationData(@PathParam("id") int id) {
        GetWeatherStationDataResult result = pipeline.getWeatherStationData(id);

        if (result.getResult().isPresent()) {  // <b class="conum">(1)</b>
            return Response.ok(result.getResult().get()).build();
        }
        else {
            return Response.status(Status.NOT_FOUND.getStatusCode(),
                    "No data found for weather station " + id).build();
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>Depending on whether a value was obtained, either return that value or a 404 response</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>With this code in place, it&#8217;s time to rebuild the application and the <code>aggregator</code> service in Docker Compose:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">mvn clean package -f aggregator/pom.xml
docker-compose stop aggregator
docker-compose up --build -d</code></pre>
</div>
</div>
<div class="paragraph">
<p>This will rebuild the <code>aggregator</code> container and restart its service.
Once that&#8217;s done, you can invoke the service&#8217;s REST API to obtain the temperature data for one of the existing stations.
To do so, you can use <code>httpie</code> in the tooling container launched before:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">http aggregator:8080/weather-stations/data/1

HTTP/1.1 200 OK
Connection: keep-alive
Content-Length: 85
Content-Type: application/json
Date: Tue, 18 Jun 2019 19:29:16 GMT

{
    "avg": 12.9,
    "count": 146,
    "max": 41.0,
    "min": -25.6,
    "stationId": 1,
    "stationName": "Hamburg"
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="scaling-out">Scaling Out</h2>
<div class="sectionbody">
<div class="paragraph">
<p>A very interesting trait of Kafka Streams applications is that they can be scaled out,
i.e. the load and state can be distributed amongst multiple application instances running the same pipeline.
Each node will then contain a subset of the aggregation results,
but Kafka Streams provides you with <a href="https://kafka.apache.org/22/documentation/streams/developer-guide/interactive-queries.html#querying-remote-state-stores-for-the-entire-app">an API</a> to obtain the information which node is hosting a given key.
The application can then either fetch the data directly from the other instance, or simply point the client to the location of that other node.</p>
</div>
<div class="paragraph">
<p>Launching multiple instances of the <code>aggregator</code> application will make look the overall architecture like so:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/guides/images/kafka-streams-guide-architecture-distributed.png" alt="Architecture with multiple aggregator nodes">
</div>
</div>
<div class="paragraph">
<p>The <code>KafkaStreamsPipeline</code> class must be adjusted slightly for this distributed architecture:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code data-lang="java" class="language-java hljs">public GetWeatherStationDataResult getWeatherStationData(int id) {
    StreamsMetadata metadata = streams.metadataForKey(                  // <b class="conum">(1)</b>
            WEATHER_STATIONS_STORE,
            id,
            Serdes.Integer().serializer()
    );

    if (metadata == null || metadata == StreamsMetadata.NOT_AVAILABLE) {
        LOG.warn("Found no metadata for key {}", id);
        return GetWeatherStationDataResult.notFound();
    }
    else if (metadata.host().equals(host)) {                            // <b class="conum">(2)</b>
        LOG.info("Found data for key {} locally", id);
        Aggregation result = getWeatherStationStore().get(id);

        if (result != null) {
            return GetWeatherStationDataResult.found(WeatherStationData.from(result));
        }
        else {
            return GetWeatherStationDataResult.notFound();
        }
    }
    else {                                                              // <b class="conum">(3)</b>
        LOG.info(
            "Found data for key {} on remote host {}:{}",
            id,
            metadata.host(),
            metadata.port()
        );
        return GetWeatherStationDataResult.foundRemotely(metadata.host(), metadata.port());
    }
}

public List&lt;PipelineMetadata&gt; getMetaData() {                           // <b class="conum">(4)</b>
    return streams.allMetadataForStore(WEATHER_STATIONS_STORE)
            .stream()
            .map(m -&gt; new PipelineMetadata(
                    m.hostInfo().host() + ":" + m.hostInfo().port(),
                    m.topicPartitions()
                        .stream()
                        .map(TopicPartition::toString)
                        .collect(Collectors.toSet()))
            )
            .collect(Collectors.toList());
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>The streams metadata for the given weather station id is obtained</p>
</li>
<li>
<p>The given key (weather station id) is maintained by the local application node, i.e. it can answer the query itself</p>
</li>
<li>
<p>The given key is maintained by another application node; in this case the information about that node (host and port) will be returned</p>
</li>
<li>
<p>The <code>getMetaData()</code> method is added to provide callers with a list of all the nodes in the application cluster.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>The <code>GetWeatherStationDataResult</code> type must be adjusted accordingly:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code data-lang="java" class="language-java hljs">package org.acme.quarkus.sample.kafkastreams.streams;

import java.util.Optional;
import java.util.OptionalInt;

import org.acme.quarkus.sample.kafkastreams.model.WeatherStationData;

public class GetWeatherStationDataResult {

    private static GetWeatherStationDataResult NOT_FOUND =
            new GetWeatherStationDataResult(null, null, null);

    private final WeatherStationData result;
    private final String host;
    private final Integer port;

    private GetWeatherStationDataResult(WeatherStationData result, String host,
            Integer port) {
        this.result = result;
        this.host = host;
        this.port = port;
    }

    public static GetWeatherStationDataResult found(WeatherStationData data) {
        return new GetWeatherStationDataResult(data, null, null);
    }

    public static GetWeatherStationDataResult foundRemotely(String host, int port) {
        return new GetWeatherStationDataResult(null, host, port);
    }

    public static GetWeatherStationDataResult notFound() {
        return NOT_FOUND;
    }

    public Optional&lt;WeatherStationData&gt; getResult() {
        return Optional.ofNullable(result);
    }

    public Optional&lt;String&gt; getHost() {
        return Optional.ofNullable(host);
    }

    public OptionalInt getPort() {
        return port != null ? OptionalInt.of(port) : OptionalInt.empty();
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Also the return type for <code>getMetaData()</code> must be defined
(<code>aggregator/src/main/java/org/acme/quarkus/sample/kafkastreams/streams/PipelineMetadata.java</code>)</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code data-lang="java" class="language-java hljs">package org.acme.quarkus.sample.kafkastreams.streams;

import java.util.Set;

public class PipelineMetadata {

    public String host;
    public Set&lt;String&gt; partitions;

    public PipelineMetadata(String host, Set&lt;String&gt; partitions) {
        this.host = host;
        this.partitions = partitions;
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Lastly, the REST endpoint class must be updated:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code data-lang="java" class="language-java hljs">package org.acme.quarkus.sample.kafkastreams.rest;

import java.net.URI;
import java.net.URISyntaxException;
import java.util.List;

import javax.enterprise.context.ApplicationScoped;
import javax.inject.Inject;
import javax.ws.rs.Consumes;
import javax.ws.rs.GET;
import javax.ws.rs.Path;
import javax.ws.rs.PathParam;
import javax.ws.rs.Produces;
import javax.ws.rs.core.MediaType;
import javax.ws.rs.core.Response;
import javax.ws.rs.core.Response.Status;

import org.acme.quarkus.sample.kafkastreams.streams.GetWeatherStationDataResult;
import org.acme.quarkus.sample.kafkastreams.streams.KafkaStreamsPipeline;
import org.acme.quarkus.sample.kafkastreams.streams.PipelineMetadata;

@ApplicationScoped
@Path("/weather-stations")
public class WeatherStationEndpoint {

    @Inject
    KafkaStreamsPipeline pipeline;

    @GET
    @Path("/data/{id}")
    @Consumes(MediaType.APPLICATION_JSON)
    @Produces(MediaType.APPLICATION_JSON)
    public Response getWeatherStationData(@PathParam("id") int id) {
        GetWeatherStationDataResult result = pipeline.getWeatherStationData(id);

        if (result.getResult().isPresent()) {                     // <b class="conum">(1)</b>
            return Response.ok(result.getResult().get()).build();
        }
        else if (result.getHost().isPresent()) {                  // <b class="conum">(2)</b>
            URI otherUri = getOtherUri(result.getHost().get(), result.getPort().getAsInt(),
                    id);
            return Response.seeOther(otherUri).build();
        }
        else {                                                    // <b class="conum">(3)</b>
            return Response.status(Status.NOT_FOUND.getStatusCode(),
                    "No data found for weather station " + id).build();
        }
    }

    @GET
    @Path("/meta-data")
    @Produces(MediaType.APPLICATION_JSON)
    public List&lt;PipelineMetadata&gt; getMetaData() {                 // <b class="conum">(4)</b>
        return pipeline.getMetaData();
    }

    private URI getOtherUri(String host, int port, int id) {
        try {
            return new URI("http://" + host + ":" + port + "/weather-stations/data/" + id);
        }
        catch (URISyntaxException e) {
            throw new RuntimeException(e);
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>The data was found locally, so return it</p>
</li>
<li>
<p>The data is maintained by another node, so reply with a redirect (HTTP status code 303) if the data for the given key is stored on one of the other nodes.</p>
</li>
<li>
<p>No data was found for the given weather station id</p>
</li>
<li>
<p>Exposes information about all the hosts forming the application cluster</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Now stop the <code>aggregator</code> service again and rebuild it.
Then let&#8217;s spin up three instances of it:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">mvn clean package -f aggregator/pom.xml
docker-compose stop aggregator
docker-compose up --build -d --scale aggregator=3</code></pre>
</div>
</div>
<div class="paragraph">
<p>When invoking the REST API on any of the three instances, it might either be
that the aggregation for the requested weather station id is stored locally on the node receiving the query,
or it could be stored on one of the other two nodes.</p>
</div>
<div class="paragraph">
<p>As the load balancer of Docker Compose will distribute requests to the <code>aggregator</code> service in a round-robin fashion,
we&#8217;ll invoke the actual nodes directly.
The application exposes information about all the host names via REST:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">http aggregator:8080/weather-stations/meta-data

HTTP/1.1 200 OK
Connection: keep-alive
Content-Length: 202
Content-Type: application/json
Date: Tue, 18 Jun 2019 20:00:23 GMT

[
    {
        "host": "2af13fe516a9:8080",
        "partitions": [
            "temperature-values-2"
        ]
    },
    {
        "host": "32cc8309611b:8080",
        "partitions": [
            "temperature-values-1"
        ]
    },
    {
        "host": "1eb39af8d587:8080",
        "partitions": [
            "temperature-values-0"
        ]
    }
]</code></pre>
</div>
</div>
<div class="paragraph">
<p>Retrieve the data from one of the three hosts shown in the response
(your actual host names will differ):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">http 2af13fe516a9:8080/weather-stations/data/1</code></pre>
</div>
</div>
<div class="paragraph">
<p>If that node holds the data for key "1", you&#8217;ll get a response like this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">HTTP/1.1 200 OK
Connection: keep-alive
Content-Length: 74
Content-Type: application/json
Date: Tue, 11 Jun 2019 19:16:31 GMT

{
  "avg": 11.9,
  "count": 259,
  "max": 50.0,
  "min": -30.1,
  "stationId": 1,
  "stationName": "Hamburg"
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Otherwise, the service will send a redirect:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">HTTP/1.1 303 See Other
Connection: keep-alive
Content-Length: 0
Date: Tue, 18 Jun 2019 20:01:03 GMT
Location: http://1eb39af8d587:8080/weather-stations/data/1</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can also have <em>httpie</em> automatically follow the redirect by passing the <code>--follow option</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code data-lang="bash" class="language-bash hljs">http --follow 2af13fe516a9:8080/weather-stations/data/1</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="running-native">Running Native</h2>
<div class="sectionbody">
<div class="paragraph">
<p>To run the <code>producer</code> and <code>aggregator</code> applications as native binaries via GraalVM,
the Maven builds can be run using the <code>native</code> profile.
As RocksDB, a dependency of Kafka Streams, uses JNI (the Java Native Interface),
one adjustment to the <code>pom.xml</code> file of the <code>aggregator</code> application is needed:
add the line <code>&lt;enableJni&gt;true&lt;/enableJni&gt;</code> to the configuration of the <code>native-image</code> execution of the Maven Quarkus plug-in,
which then should look like so:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code data-lang="xml" class="language-xml hljs">&lt;plugin&gt;
  &lt;groupId&gt;io.quarkus&lt;/groupId&gt;
  &lt;artifactId&gt;quarkus-maven-plugin&lt;/artifactId&gt;
  &lt;version&gt;${quarkus.version}&lt;/version&gt;
  &lt;executions&gt;
    &lt;execution&gt;
      &lt;goals&gt;
        &lt;goal&gt;native-image&lt;/goal&gt;
      &lt;/goals&gt;
      &lt;configuration&gt;
        &lt;enableHttpUrlHandler&gt;true&lt;/enableHttpUrlHandler&gt;
        &lt;enableJni&gt;true&lt;/enableJni&gt;
      &lt;/configuration&gt;
    &lt;/execution&gt;
  &lt;/executions&gt;
&lt;/plugin&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>The build the two applications like so:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code data-lang="shell" class="language-shell hljs">mvn clean package -f producer/pom.xml -Pnative -Dnative-image.container-runtime=docker
mvn clean package -f aggregator/pom.xml -Pnative -Dnative-image.container-runtime=docker</code></pre>
</div>
</div>
<div class="paragraph">
<p>Now create an environment variable named <code>QUARKUS_MODE</code> and with value set to "native":</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code data-lang="shell" class="language-shell hljs">export QUARKUS_MODE=native</code></pre>
</div>
</div>
<div class="paragraph">
<p>This is used by the Docker Compose file to use the correct <code>Dockerfile</code> when building the <code>producer</code> and <code>aggregator</code> images.
The Kafka Streams application can work with less than 50 MB RSS in native mode.
To do so, add the <code>Xmx</code> option to the program invocation in <code>aggregator/src/main/docker/Dockerfile.native</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code data-lang="shell" class="language-shell hljs">CMD ["./application", "-Dquarkus.http.host=0.0.0.0", "-Xmx32m"]</code></pre>
</div>
</div>
<div class="paragraph">
<p>Now start Docker Compose as described above
(don&#8217;t forget to rebuild the container images).</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="going-further">Going Further</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This guide has shown how you can build stream processing applications using Quarkus and the Kafka Streams APIs,
both in JVM and native modes.
For running your KStreams application in production, you could also add health checks and metrics for the data pipeline.
Refer to the Quarkus guides on <a href="/guides/metrics-guide">metrics</a> and <a href="/guides/health-guide">health checks</a> to learn more.</p>
</div>
</div>
</div>
  </div>
</div>

  </div>

  <div class="content project-footer">
  <div class="footer-section">
    <div class="logo-wrapper">
      <a href="/"><img src="/assets/images/quarkus_logo_horizontal_rgb_reverse.svg" class="project-logo" title="Quarkus"></a>
    </div>
  </div>
  <div class="grid-wrapper">
    <p class="grid__item width-3-12">Quarkus is open. Quarkus and its extensions are available under the <a href='https://www.apache.org/licenses/LICENSE-2.0' target='_blank'>Apache Software License 2.0</a> or compatible license.<br /><br />This website was built with <a href='https://jekyllrb.com/' target='_blank'>Jekyll</a> is hosted on <a href='https://pages.github.com/' target='_blank'>Github Pages</a> and is completely open source. If you want to make it better, <a href='https://github.com/quarkusio/quarkusio.github.io' target='_blank'>fork the website</a> and show us what you’ve got.</p>

    
      <div class="width-1-12 project-links">
        <span>Navigation</span>
        <ul class="footer-links width-1-12">
          
            <li><a href="/">Home</a></li>
          
            <li><a href="/guides">Guides</a></li>
          
            <li><a href="/get-started">Get Started</a></li>
          
        </ul>
      </div>
    
      <div class="width-1-12 project-links">
        <span>Contribute</span>
        <ul class="footer-links width-1-12">
          
            <li><a href="https://twitter.com/quarkusio">Follow us</a></li>
          
            <li><a href="https://github.com/quarkusio">GitHub</a></li>
          
        </ul>
      </div>
    
      <div class="width-1-12 project-links">
        <span>Get Help</span>
        <ul class="footer-links width-1-12">
          
            <li><a href="https://quarkusio.zulipchat.com">Chatroom</a></li>
          
            <li><a href="https://groups.google.com/forum/#!forum/quarkus-dev">Google&nbsp;Groups</a></li>
          
            <li><a href="/faq">FAQ</a></li>
          
        </ul>
      </div>
    

    
      <div class="width-6-12 more-links">
        <span>Quarkus is proudly made of</span>
        <ul class="footer-links">
          
            <li><a href="https://hibernate.org" target="_blank">Hibernate</a></li>
          
            <li><a href="https://netty.io" target="_blank">Netty</a></li>
          
            <li><a href="https://resteasy.github.io" target="_blank">RESTEasy</a></li>
          
            <li><a href="https://microprofile.io" target="_blank">Eclipse MicroProfile</a></li>
          
            <li><a href="https://vertx.io/" target="_blank">Eclipse Vert.x</a></li>
          
            <li><a href="https://camel.apache.org" target="_blank">Apache Camel</a></li>
          
        </ul>
      </div>
    
  </div>
</div>
  <div class="content redhat-footer">
  <div class="grid-wrapper">
    <span class="licence">
      <i class="fab fa-creative-commons"></i><i class="fab fa-creative-commons-by"></i> <a href="https://creativecommons.org/licenses/by/3.0/" target="_blank">CC by 3.0</a>
      | <a href="https://www.redhat.com/en/about/privacy-policy">Red Hat Privacy Policy</a>
    </span>
    <span class="redhat">
      a Red Hat sponsored project   
    </span>
    <span class="redhat-logo">
      <a href="https://www.redhat.com/" target="_blank"><img src="/assets/images/redhat_reversed.svg"></a>
    </span>
  </div>
</div>


  <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js"></script>
  <script type="text/javascript" src="/assets/javascript/mobile-nav.js"></script>
  <script type="text/javascript" src="/assets/javascript/scroll-down.js"></script>
  <script type="text/javascript">
    if (("undefined" !== typeof _satellite) && ("function" === typeof _satellite.pageBottom)) {
        _satellite.pageBottom();
    }
  </script>
</body>

</html>
